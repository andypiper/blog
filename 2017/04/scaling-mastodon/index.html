<!doctype html><html lang><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=generator content="Hugo 0.124.1"><title>Scaling Mastodon - Mastodon Blog</title>
<link rel="shortcut icon" type=image/png href=https://blog.joinmastodon.org/favicon.ico><link rel=canonical href=https://blog.joinmastodon.org/2017/04/scaling-mastodon/><link rel=stylesheet href="https://blog.joinmastodon.org/css/styles.min.0ff7db6851f0326dde45ec59418290e69bcc519b34c9063e48b11e912473c286.css" integrity="sha256-D/fbaFHwMm3eRexZQYKQ5pvMUZs0yQY+SLEekSRzwoY="><meta property="og:locale" content><meta property="og:type" content="article"><meta property="og:title" content="Scaling Mastodon"><meta property="og:description" content="My instance mastodon.social has recently surpassed 43,000 users. I have closed registrations both to have more time to investigate the infrastructure and ensure a good experience for existing users, and to encourage more decentralization in the network (with a wonderful effect — the Mastodon fediverse now hosts over 161,000 people spread out over more than 500 independent instances!)
But providing a smooth and swift service to 43,000 users takes some doing, and as some of the other instances are approaching large sizes themselves, it is a good time to share the tips &amp;amp; tricks I learned from doing it."><meta property="og:url" content="https://blog.joinmastodon.org/2017/04/scaling-mastodon/"><meta property="og:site_name" content="Mastodon Blog"><meta name=article:author content="Eugen Rochko"><meta name=fediverse:creator content="Gargron@mastodon.social"></head><body><div class="bg-white py-12 sm:py-32"><div class="mx-auto max-w-7xl px-6 lg:px-8"><article class=h-entry><header class="max-w-prose mx-auto relative"><div class="flex flex-wrap items-center gap-x-4 text-xs mb-8"><a href=/ class="inline-flex items-center font-bold text-blurple-600 hover:underline hover:text-blurple-500"><svg class="icon arrow-small-left-icon w-5 h-5" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentcolor" class="w-5 h-5"><path fill-rule="evenodd" d="M15 10a.75.75.0 01-.75.75H7.612l2.158 1.96a.75.75.0 11-1.04 1.08l-3.5-3.25a.75.75.0 010-1.08l3.5-3.25a.75.75.0 111.04 1.08L7.612 9.25h6.638A.75.75.0 0115 10z" clip-rule="evenodd"/></svg> Back</a>
<time class="text-gray-500 dt-published" datetime=2017-04-12T00:00:00Z>Apr 12, 2017</time><div class="flex flex-wrap items-center gap-x-4"><a class="relative z-10 rounded-full bg-nightshade-50 text-nightshade-900 px-3 py-1.5 font-medium hover:text-nightshade-600 whitespace-nowrap" href=/categories/guides>Guides</a></div></div><h1 class="p-name text-3xl font-bold tracking-tight text-gray-900 sm:text-4xl">Scaling Mastodon</h1><h2 class="text-xl leading-8 text-gray-700 mt-2">What it takes to house 43,000 users</h2><div class="relative mt-8 flex items-center gap-x-4"><div class="h-10 w-10 rounded-full bg-blurple-gradient relative overflow-hidden"><img src=https://blog.joinmastodon.org/authors/eugen-rochko.jpg alt class="absolute w-full h-full object-cover"></div><div class="text-sm leading-6"><p class="font-semibold text-gray-900"><span class="absolute inset-0"></span>
Eugen Rochko</p><p class=text-gray-600>CEO / Founder</p></div></div></header><main class="e-content max-w-prose mx-auto prose mt-8"><p>My instance <a href=https://mastodon.social>mastodon.social</a> has recently surpassed 43,000 users. I have closed registrations both to have more time to investigate the infrastructure and ensure a good experience for existing users, and to encourage more decentralization in the network (with a wonderful effect — the Mastodon fediverse now hosts <a href=https://instances.mastodon.xyz/>over 161,000 people spread out over more than 500 independent instances</a>!)</p><p>But providing a smooth and swift service to 43,000 users takes some doing, and as some of the other instances are approaching large sizes themselves, it is a good time to share the tips & tricks I learned from doing it.</p><p>Mastodon consists of two parts that scale differently: databases, and code. Databases scale vertically. That means, it’s a lot easier and more cost efficient to buy a super beefy machine for your database, than it is to spread the database over multiple machines with sharding or replication. The Mastodon code on the other hand, scales horizontally — run it from as many machines as you want, concurrently, and load balance the web requests, and you’re good.</p><p>First of all, where does the load on Mastodon come from?</p><p>The act of browsing and using the site requires the user’s HTTP requests to be answered. Every Puma worker (WEB_CONCURRENCY) can answer MAX_THREADS of requests at the same time. If every worker’s every thread is busy answering something, the new request must wait. If it has to wait too long, it is canceled with a timeout. <strong>That means, you need more workers and threads to be able to handle a higher request throughput.</strong></p><p>Being connected to the streaming API means a constantly open connection through nginx to the streaming API service. The streaming API itself, I do not notice being strained from a high number of connections, but <strong>nginx requires a high limit on open files (worker_rlimit_nofile) and a high number of worker_connections to keep the connections up.</strong> Thankfully, nginx is quite lightweight even with such high parameters.</p><p>Actual activity on the site, like sending messages, following or unfollowing people, and many more things that people can do, all generates background jobs that must be processed by Sidekiq. If they are not processed in time, they start queuing up in a backlog, and it becomes noticeable when a toot you wrote reaches your followers only 1 hour later. <strong>That means, more Sidekiq workers are needed to be able to process more activity.</strong></p><p>Those are the basic principles of Mastodon scaling. However, there is more.</p><p>Each time you scale horizontally, you are putting more strain on the database, because web workers and background workers and the streaming API all need database connections. Each service uses connection pools to provide for their threads. This can go up to 200 connections overall easily, which is the recommended max_connections on a PostgreSQL database with 16GB of RAM. When you reach that point, it means you need pgBouncer. <a href=https://pgbouncer.github.io/usage.html#quick-start>pgBouncer </a>is a transparent proxy for PostgreSQL that provides pooling based on database <em>transactions</em>, rather than <em>sessions</em>. That has the benefit that a real database connection is not needlessly occupied while a thread is doing nothing with it. Mastodon supports pgBouncer, you simply need to connect to it instead of PostgreSQL, and set the environment variable PREPARED_STATEMENTS=false</p><p>Simply spinning up more Sidekiq processes with the default recommended settings may not be the silver bullet for processing user activity in time. Not all background jobs are created equal! There are different queues, with different priorities, which Sidekiq works with. In Mastodon, these queues are:</p><ul><li><strong>default</strong>: responsible for distribution of toots into local follower’s timelines</li><li><strong>push</strong>: delivery of toots to other servers and processing of toots incoming from other servers, before they are queued up for distribution to local followers</li><li><strong>pull</strong>: download of conversations, user avatars and headers, profile information</li><li><strong>mailers</strong>: sending of e-mail through the SMTP server</li></ul><p>I have ordered them in the order of importance. The default queue is the most important, because it directly and instantly affects user experience on your Mastodon instance. Push is also important, because it affects your followers and contacts from other places. Pull is less important, because downloading that information can wait without much harm. And finally, mailers — there is usually not that much e-mail being sent from Mastodon, anyway.</p><p>When you have a Sidekiq process with a defined order of queues like -q default -q push -q pull -q mailers, it first checks the first queue, if nothing is there, the next one, etc. That is, each thread defined by the -c (concurrency) parameter, does that. But I think you must see the problem — if you suddenly have 100 jobs in the default queue, and 100 in the push queue, and you only have 25 threads working on all of them, there will be a huge delay before Sidekiq will ever get to the push ones.</p><p>For this reason, I found it useful to split queues between different Sidekiq processes on different machines. A couple responsible only for the default queue, a couple only responsible for push, pull, etc. This way, you are not getting too much delay on any type of user-facing action.</p><p>Another big revelation, though obvious in hindsight, is that it is less effective to set a high concurrency setting on a single Sidekiq process, than it is to spin up a couple independent Sidekiq processes with lower concurrency settings. Actually, the same is true for Puma workers — more workers with less threads work faster than less workers with more threads. This is because MRI Ruby does not have native threads, so they cannot be run truly in parallel, no matter how many CPUs you have. The only drawback is this: While threads share the same memory, separate processes don’t. That means, more separate processes consumes more RAM. But if you have free RAM on your server doing nothing, it means you should split up a worker into more workers with less threads.</p><p>The current mastodon.social infrastructure looks like this:</p><p>2x baremetal C2M (8 cores,16GB RAM) servers:</p><ul><li>1 running PostgreSQL (with pgBouncer on top) and Redis</li><li>1 running 4x Sidekiq processes between 10–25 threads each</li></ul><p>6x baremetal C2S (4 cores, 8GB RAM) servers:</p><ul><li>2 running Puma (8x workers, 2x threads each), Sidekiq (10 threads), streaming API</li><li>1 running Nginx load balancer, Puma (8x workers, 2x threads each, Sidekiq (2 threads), streaming API</li><li>2 running Sidekiq (20 threads)</li><li>1 running Minio for file storage with a 150GB volume</li></ul><p>Most of these are new additions since the surge of Internet attention — before that mastodon.social was serving 20,000 users (most of whom were, to be fair, not active the same time) with just the DB server, 2 app servers and 1 Minio server. At the same time, the v1.1.1 release of Mastodon includes a variety of optimizations that at least doubled the throughput of requests and background jobs compared to the first day of going viral.</p><p>At the time of writing, mastodon.social is servicing about 6,000 open connections, with about 3,000 RPM and an average response time of 200ms.</p></main></article><div class="grid grid-cols-1 gap-x-8 gap-y-16 border-t border-gray-200 pt-10 sm:mt-16 sm:pt-16 md:grid-cols-2 h-feed"><a href=/2017/03/two-reasons-why-organizations-should-switch-to-self-hosting-social-media/ class="group flex lg:max-w-xl flex-col items-start justify-between h-entry u-url" rel=bookmark><div class=w-full><div class="flex items-center gap-x-4 text-xs"><time class="text-gray-500 dt-published" datetime=2017-03-16T00:00:00Z>Mar 16, 2017
</time><span class="relative z-10 rounded-full bg-nightshade-50 text-nightshade-900 px-3 py-1.5 font-medium">Op-Ed</span></div><div class="w-full relative aspect-[3/2] w-full overflow-hidden rounded-md my-4 bg-blurple-gradient shadow-lg ring-blurple-500 group-hover:ring-2"></div><div class=relative><h3 class="mt-3 text-lg font-semibold leading-6 text-gray-900 group-hover:text-blurple-500 p-name"><span class="absolute inset-0"></span>
Two reasons why organizations should switch to self-hosting social media</h3><p class="mt-5 line-clamp-3 text-sm leading-6 text-gray-600 p-summary">My name is Eugen Rochko and I’m the creator of Mastodon, a free, open-source federated social network server. The flagship instance mastodon.social has over 23,000 users and is growing fast. You can check it out here.
If your organization is hosting a Mastodon instance, it is essentially a self-perpetuating brand awareness campaign. When people from other instances talk to or follow your users, they see your domain name all the time, since it is part of their globally unique usernames.</p></div></div><div class="relative mt-8 flex items-center gap-x-4"><div class="h-10 w-10 rounded-full bg-blurple-gradient relative overflow-hidden"><img src=https://blog.joinmastodon.org/authors/eugen-rochko.jpg alt class="absolute w-full h-full object-cover"></div><div class="text-sm leading-6"><p class="font-semibold text-gray-900"><span class="absolute inset-0"></span>
Eugen Rochko</p><p class=text-gray-600>CEO / Founder</p></div></div></a><a href=/2017/03/learning-from-twitters-mistakes/ class="group flex lg:max-w-xl flex-col items-start justify-between h-entry u-url" rel=bookmark><div class=w-full><div class="flex items-center gap-x-4 text-xs"><time class="text-gray-500 dt-published" datetime=2017-03-03T00:00:00Z>Mar 3, 2017
</time><span class="relative z-10 rounded-full bg-nightshade-50 text-nightshade-900 px-3 py-1.5 font-medium">New Features</span></div><div class="w-full relative aspect-[3/2] w-full overflow-hidden rounded-md my-4 bg-blurple-gradient shadow-lg ring-blurple-500 group-hover:ring-2"></div><div class=relative><h3 class="mt-3 text-lg font-semibold leading-6 text-gray-900 group-hover:text-blurple-500 p-name"><span class="absolute inset-0"></span>
Learning from Twitter’s mistakes</h3><p class="mt-5 line-clamp-3 text-sm leading-6 text-gray-600 p-summary">My name is Eugen Rochko and I’m the creator of Mastodon, a free, open-source federated social network server. The flagship instance mastodon.social has over 22,000 users and is growing fast. You can check it out here.
Very early on in the development of Mastodon I’ve decided that centralization and unexpected algorithmic changes were not the only one of Twitter’s problems. Harrassment and tools to deal with it have always been lacking on Twitter’s end.</p></div></div><div class="relative mt-8 flex items-center gap-x-4"><div class="h-10 w-10 rounded-full bg-blurple-gradient relative overflow-hidden"><img src=https://blog.joinmastodon.org/authors/eugen-rochko.jpg alt class="absolute w-full h-full object-cover"></div><div class="text-sm leading-6"><p class="font-semibold text-gray-900"><span class="absolute inset-0"></span>
Eugen Rochko</p><p class=text-gray-600>CEO / Founder</p></div></div></a></div><footer class="border-t border-gray-200 pt-10 mt-10 text-gray-600"><div class="flex justify-between"><p class=flex-0><a class=hover:underline href=https://joinmastodon.org>Mastodon</a> · <a class=hover:underline href=https://github.com/mastodon/blog/blob/master/content//posts/2017-04-12_scaling-mastodon>View source</a> · <a class=hover:underline href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA 4.0</a> · <a class=hover:underline href=https://joinmastodon.org/imprint>Imprint</a></p><p class="flex-0 justify-end flex gap-x-4 items-center"><a class=hover:text-blurple-500 href=https://mastodon.social/@Mastodon target=_blank><svg class="icon mastodon-icon w-5 h-5" width="74" height="79" viewBox="0 0 74 79" fill="currentcolor" xmlns="http://www.w3.org/2000/svg"><path d="M73.7014 17.9592C72.5616 9.62034 65.1774 3.04876 56.424 1.77536 54.9472 1.56019 49.3517.7771 36.3901.7771H36.2933c-12.9652.0-15.7468.78309-17.2236.99826C10.56 3.01348 2.78877 8.91838.903306 17.356-.00357857 21.5113-.100361 26.1181.068112 30.3439.308275 36.404.354874 42.4535.91406 48.489c.38658 4.009 1.06096 7.9861 2.01809 11.9015 1.79226 7.2312 9.04735 13.249 16.15545 15.704C26.6979 78.6548 34.8821 79.0799 42.724 77.3221 43.5866 77.1245 44.4398 76.8953 45.2833 76.6342 47.1867 76.0381 49.4199 75.3714 51.0616 74.2003 51.0841 74.1839 51.1026 74.1627 51.1156 74.1382 51.1286 74.1138 51.1359 74.0868 51.1368 74.0592V68.2108C51.1364 68.185 51.1302 68.1596 51.1185 68.1365 51.1069 68.1134 51.0902 68.0932 51.0695 68.0773 51.0489 68.0614 51.0249 68.0503 50.9994 68.0447 50.9738 68.0391 50.9473 68.0392 50.9218 68.045c-5.0242 1.181-10.1727 1.773-15.3382 1.7637C26.694 69.8087 24.3031 65.6569 23.6184 63.9285 23.0681 62.4347 22.7186 60.8764 22.5789 59.2934 22.5775 59.2669 22.5825 59.2403 22.5934 59.216 22.6043 59.1916 22.621 59.1702 22.6419 59.1533 22.6629 59.1365 22.6876 59.1248 22.714 59.1191 22.7404 59.1134 22.7678 59.1139 22.794 59.1206 27.7345 60.2936 32.799 60.8856 37.8813 60.8843c1.2223.0 2.441.0 3.6634-.0317000000000007C46.6562 60.7115 52.0437 60.454 57.0728 59.4874 57.1983 59.4628 57.3237 59.4416 57.4313 59.4098c7.9325-1.4991 15.4815-6.2047 16.2486-18.1203C73.7086 40.8204 73.7803 36.3758 73.7803 35.889 73.7839 34.2347 74.3216 24.1533 73.7014 17.9592zM61.4925 47.6918H53.1514V27.5855c0-4.2329-1.7923-6.3917-5.4378-6.3917-4.0075.0-6.0148 2.5538-6.0148 7.5981V39.7974h-8.291V28.7919c0-5.0443-2.0109-7.5981-6.0184-7.5981-3.624.0-5.4342 2.1588-5.4378 6.3917V47.6918h-8.334V26.9752c0-4.2329 1.0981-7.5957 3.2942-10.0884 2.2654-2.4868 5.237-3.7637 8.9255-3.7637 4.2691.0 7.4952 1.6155 9.6459 4.8431L37.5587 21.3949l2.079-3.4287c2.1507-3.2276 5.3768-4.8431 9.6388-4.8431 3.6849.0 6.6564 1.2769 8.929 3.7637 2.1962 2.4904 3.2942 5.8532 3.2942 10.0884L61.4925 47.6918z" fill="inherit"/></svg></a>
<a class=hover:text-blurple-500 href=/index.xml target=_blank><svg class="icon rss-icon w-5 h-5" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentcolor"><path d="M3.75 3A.75.75.0 003 3.75v.5c0 .414.336.75.75.75H4c6.075.0 11 4.925 11 11v.25c0 .414.336.75.75.75h.5a.75.75.0 00.75-.75V16C17 8.82 11.18 3 4 3h-.25z"/><path d="M3 8.75A.75.75.0 013.75 8H4a8 8 0 018 8v.25a.75.75.0 01-.75.75h-.5a.75.75.0 01-.75-.75V16a6 6 0 00-6-6h-.25A.75.75.0 013 9.25v-.5zM7 15a2 2 0 11-4 0 2 2 0 014 0z"/></svg></a></p></div></footer></div></div></body></html>